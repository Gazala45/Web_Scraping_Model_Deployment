# Web_Scraping_Model_Deployment
Scraping using requests, beautifulsoup4, specific pages of https://www.goauto.ca/ website into a data frame, deployed onto heroku server using streamlit!

Kindly follow the below steps to run this program
1) in terminal/anaconda prompt cd to desired directory where this project will be stored
2) download all files into the above directory/folder
3) create an environment-> conda create -n web_scrape python=3.8
4) activate the environment-> conda activate web_scrape
5) install beautiful soup4-> pip install bs4
6) install jupyter-> pip install jupyter
7) install requests-> pip install requests
8) install streamlit-> pip install streamlit
9) run the app python file using streamlit->streamlit run ws1.py
10) open the browser page to run
11) input should be as follows

a) URL: https://www.goauto.ca/ 
b) Section: inventory 
c) Page Number: 1 or 2
d) press process button


12) please use below link to the model 👍 https://goauto-web-scrap-app.herokuapp.com/, repeat step 11


